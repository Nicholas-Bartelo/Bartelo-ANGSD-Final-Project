---
title: "Download and Begin Processing Data"
author: "Nick Bartelo"
date: "2/21/2021"
output:
  html_document:
    df_print: paged
---


## Q1 

1. Download at least one FASTQ file that you will be working with for your project. Document the following details:

* Where did you get it from?
* What publication is it linked to?
* Who generated the data?
* How was the NA extracted?
* What library prep was used?
* What cell type was used?
* What was the treatment/experimental condition?
* What sequencing platform was used?

To begin answering this question, we first create a new folder in the SCU by first navigating to /home/nib4003/ANGSD_2021_hw/ and using the command `mkdir final_project`. Here we will store all our files we use for the final project as the semester progresses. We then began our data download by navigating to https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE107489 where we see the 9 samples of mice to be sequenced. Under Supplementary file we click 'SRA Run Selector'. On this page, we first clicked the blue checkmark box to highlight all runs, and under Download we clicked 'Accession List' which downloaded a file with all accession numbers for the files. Using WinSCP, we then transferred this file to the final_project folder in the SCU. Next, we used the SRA toolkit, following the documentation here: https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/ which told us how to download the files. This required the SRA toolkit, which we found in the SCU using the command `spack find` and loaded into the SCU using the command `spack load sra-toolkit@2.10.7%gcc@6.3.0`. Once this command is run, we can use SRA toolkit to get the fastq files, beginning with the following code. 

```{bash,eval=FALSE}
prefetch --option-file SRR_Acc_List.txt
```

Prefetch is a program which downloads Runs (sequence files in the compressed SRA format) and all additional data necessary to convert the Run from the SRA format to a more commonly used format, in our case fastq. The `--option-file` part of the command allows us to pass our list of accession numbers instead of one accession number at a time. We next extracted all fastq files using the following code. 

```{bash,eval=FALSE}
fastq-dump SRR6329219 SRR6329221 SRR6329224 SRR6329225 SRR6329226 SRR6329227 SRR6329223 SRR6329220 SRR6329222
```
This resulted in a list of fastq files named accession_number.fastq. This process does take some time to complete. 

The publication this is linked to is found at https://link.springer.com/article/10.1007%2Fs12022-018-9523-x and has the title "RNA-Seq Analysis of Islets to Characterise the Dedifferentiation in Type 2 Diabetes Model Mice db/db". The data was generated by Abraham Neelankal John, Ramesh Ram, and Fang-Xu Jiang. 

The RNA was extracted using the following method. The pancreas was perfused after sacrificing each mouse by CO2 asphyxiation. The islets of Langerhans, tissue-resident macrophages of the skin, were purified by perfusing the pancreas with 3 ml of collagenase-p (1 IU/mL) dissolved in RPMI. Density gradient centrifugation was used to separate the islets from the digested pancreas. The collagenase dispersed islets were used for RNA extraction on the same day, although these islets have a viability of 4–5 days in RPMI. The total RNA of the isolated islets was extracted using TRIzol (Invitrogen) in accordance with the manufacturer’s protocol. TRIzol reagent lysed islet cells were mixed with chloroform and centrifuged to remove RNA upper aqueous phase from the lower organic phase. RNA in the upper aqueous phase was precipitated by isopropanol and centrifuged to precipitate RNA. This precipitated RNA were washed with 75% alcohol and dissolved in RNAse/DNAse-free water (Invitrogen). A Nanodrop ND-1000 spectrophotometer (Australian Biolab Group, Melbourne, Australia) was used to quantify the concentration of RNA. The RNA-Seq was performed by AGRF and the resulting RNA-Seq read was used to perform the analysis. The isolated RNA of a concentration of 100 ng of $RNA/(1 \mu$L) was reverse transcribed to generate the complementary DNA (cDNA) in a reaction with a total volume of 20 $\mu$L (2000 ng/reaction) using the Invitrogen protocol. Real-time PCR was performed using working standard of cDNA by diluting 2 $\mu$L of cDNA in 1000 $\mu$L of RNAse- and DNAse-free water. 

The Illumina Hi-seq 2500 platform was used for RNA-seq, and 50 BP reads were generated for the islets collected from all nine mice. The data yield per individual mice islet ranged from 1.02 to 1.23 Gb. The library for RNA-seq was prepared using Illumina’s Ribo Zero Gold protocol. The library strategy is RNA-seq, with source transcriptomic, and selection cDNA. The Illumina bcl2fastq 2.20.0.422 pipeline was used to generate primary sequence read sequence with Illumina quality scores (phred-like quality +33). All the samples were checked for cross-species contamination.

The experimental condition was 12-week-old mice with a random blood glucose of 7-8 mM, 9-10 mM and 23-28 mM blood glucose within wild-type, db/db, and db/+ respectively. The sequencing platform was Illumina HiSeq 2500 (Mus musculus).

## Q2

2. Align the FASTQ file with an appropriate aligner (you may have to build a new index). Document:

* Parameters (and why you chose them)
* Summary of outcome and basic QC

The first thing we do is rename the files so that they are labeled in a manner which we know right away which phenotype the mouse has. We show an example for a mouse who is heterozygous, which we name heterozygous_sample1.fastq. The naming convention is diabetes for db_db (-/-), heterozygous for (+/-), and wt for wild type (+/+). 

```{bash,eval=FALSE}
mv SRR6329219.fastq heterozygous_sample1.fastq
```

After renaming all 9 samples, we then gzip all files so that we can they are compressed and then we will transfer them to the scratch workspace. To do this we use the command `gzip *.fastq`. We now can copy the files to the scratch directory nib4003_6957583 first navigating to this directory and using the command

```{bash,eval=FALSE}
cp /home/nib4003/ANGSD_2021_hw/final_project/*.fastq.gz .
```

where the '.' at the end signifies that we want the files copied into the current directory.

We next need to download the reference genome and the annotations. After talking with Merv, he said to go to the website https://www.gencodegenes.org/mouse/release_M25.html which contains the most up to date information for the mouse genome used, which is GRCm38.p6. There are columns that describe the contents and regions of the files. Merv said for my data I should take the genome annotations (.gtf) file for the primary "PRI" under Regions for the Comprehensive gene annotation files under Content. To download the reference genome, we used the command `wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.primary_assembly.annotation.gtf.gz` in the SCU. We then also downloaded the PRI Genome sequence, primary assembly (GRCm38) fasta file using the command `wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz`. Once we had both files downloaded, we wanted to unzip them for use in genome indexing, which we did using the commands `zcat gencode.vM25.primary_assembly.annotation.gtf.gz > gencode.vM25.primary_assembly.annotation.gtf` and `zcat GRCm38.primary_assembly.genome.fa.gz > GRCm38.primary_assembly.genome.fa`. Next, we copied all our files to the scratch/nib4003_6613733 directory using the command `cp /path/to/filename .` when in this directory for all files. In this directory, we created a new directory to store the output genome index using the command `mkdir star_mouse_genome_index`. 

Before any alignment occurs, we first need to run initial qc using fastqc on our files. We do this using the command below after first loading it using the command `spack load fastqc`.

```{bash,eval=FALSE}
for file in *fastq.gz; do fastqc $file --extract; done
```


The next step is to run multiqc on our files output from fastqc so that we can better visualize if there are any problems related to the initial reads. To do this, we first load it using `spack load -r py-multiqc` and then we use the command below.

```{bash,eval=FALSE}
mutliqc /home/nib4003/ANGSD_2021_hw/final_project/
```

We then export the results of multiqc to the computer using WinSCP as previously done throughout the course. By inspecting the multiqc, we see that there are potential problems with the GC content and overrepresented sequences of diabetes sample 3 reads, as well as the sequence duplication levels of all three diabetes samples. However, the results seem to not be too extreme. When I asked Merv about this, he agreed and said, "Since it seems to be high GC content reads that are duplicated, it could be that they simply ran the PCR amplification during library prep too long. This isn’t a concern at this step and there are strategies to collapse PCR duplicates later. At this stage I think it’d be sufficient to note it, and maybe try to figure out what reads are overrepresented, i.e., BLAST some of their sequences." Therefore, we note that we need to look into BLAST later on and we can proceed with the STAR alignment.

Now that we have the reference genome and annotations, and we know there are no major problems with our initial reads, we can make the genome index in order to align the reads. We first have to import STAR using `spack load star@2.7.0e` and samtools using `spack load samtools@1.9%gcc@6.3.0`. The generation of the genome index is done using the command below. 

```{bash,eval=FALSE}
STAR --runMode genomeGenerate --runThreadN 16 --genomeDir /scratch/nib4003_6613733/star
_mouse_genome_index --genomeFastaFiles GRCm38.primary_assembly.genome.fa --sjdbGTFfile gencode.vM25.primary_assembly.ann
otation.gtf --sjdbOverhang 49
```

I talked with Merv about many of the parameters for STAR and decided to leave most of them at the default value for the mouse genome. Merv said to use a `runThreadN` of 16 if possible to get the job done more quickly, and we discussed the setting of `sjdbOverhang` to 49 bp because the reads are 50 bp long. All other arguments in the genome index generation are standard. Now that the genome index is created, we can run STAR alignment using the code below for the first diabetes mouse sample.

```{bash,eval=FALSE}
STAR --runMode alignReads --runThreadN 16 --genomeDir star_mouse_genome_index --readFilesIn diabetes_sample1.fastq.gz --readFilesCommand zcat --outFileNamePrefix diabetes_sample1_alignments. --outSAMtype BAM SortedByCoordinate --outSAMattributes All
```

The code above again takes a `runThreadN` count of 16 and mostly default values. We return the alignments in a sorted BAM file, which we also return all SAM attributes STAR offers, which are shown in the table below. These may be useful in finding information about the reads later on. STAR Optional Fields - Taken from https://physiology.med.cornell.edu/faculty/skrabanek/lab/angsd/lecture_notes/STARmanual.pdf:

Tag |	Meaning
--- | ---
NH | Number of reported alignments that contain the query in the current record
HI | Query hit index
AS | Alignment score generated by aligner
nM | Number of mismatches per (paired) alignment,
NM | Edit distance to the reference
MD | String for mismatching positions
jM | Intron motifs for all junctions
jI | Start and End of introns for all junctions
MC | CIGAR string for mate/next segment

We actually ran the above STAR code in two bash scripts using slurm so that it would work more efficiently. With a lot of help from Merv, the final product is shown below which we passed as a job to slurm. The first is for genome creation and the second is for alignment. 

```{bash,eval=FALSE}
#! /bin/bash -l

#SBATCH --account=angsd_class
#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --job-name=mouse_genome_creation
#SBATCH --time=12:34:00
#SBATCH --mem=35G

echo "Starting at:" `date` >> hello_slurm_output.txt
sleep 30
echo "This is job #:" $SLURM_JOB_ID >> hello_slurm_output.txt
echo "Running on node:" `hostname` >> hello_slurm_output.txt
echo "Running on cluster:" $SLURM_CLUSTER_NAME >> hello_slurm_output.txt
echo "This job was assigned the temporary (local) directory:" $TMPDIR >> hello_slurm_output.txt

spack load star@2.7.0e
rm -rf /scratch/nib4003/STARtmp
mkdir -p /scratch/nib4003

STAR --runMode genomeGenerate --runThreadN 16 --genomeDir /home/nib4003/ANGSD_2021_hw/final_project/star_mouse_genome_index --genomeFastaFiles /home/nib4003/ANGSD_2021_hw/final_project/GRCm38.primary_assembly.genome.fa --sjdbGTFfile /home/nib4003/ANGSD_2021_hw/final_project/gencode.vM25.primary_assembly.annotation.gtf --sjdbOverhang 49 --outTmpDir /scratch/nib4003/STARtmp

exit
```

```{bash,eval=FALSE}
#! /bin/bash -l

#SBATCH --account=angsd_class
#SBATCH --partition=angsd_class                                                                                         #SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --job-name=mouse_genome_creation
#SBATCH --time=12:34:00
#SBATCH --mem=35G

echo "Starting at:" `date` >> hello_slurm_output.txt
sleep 30
echo "This is job #:" $SLURM_JOB_ID >> hello_slurm_output.txt
echo "Running on node:" `hostname` >> hello_slurm_output.txt
echo "Running on cluster:" $SLURM_CLUSTER_NAME >> hello_slurm_output.txt
echo "This job was assigned the temporary (local) directory:" $TMPDIR >> hello_slurm_output.txt

spack load star@2.7.0e
rm -rf /scratch/nib4003/STARtmp

STAR --runMode alignReads --runThreadN 16 --genomeDir /home/nib4003/ANGSD_2021_hw/final_project/star_mouse_genome_index --readFilesIn /home/nib4003/ANGSD_2021_hw/final_project/diabetes_sample1.fastq.gz --readFilesCommand zcat --outFileNamePrefix diabetes_sample1_alignments. --outSAMtype BAM SortedByCoordinate --outSAMattributes All --outTmpDir /scratch/nib4003/STARtmp

exit
```

Here, we also create a temporary directory to keep the STAR files for more efficiency using `--outTmpDir /scratch/nib4003/STARtmp`. This folder cannot be created before running the script so we ensure this before running STAR with the command `rm -rf /scratch/nib4003/STARtmp`. The genome indexing script take a long time (9 hours!!!) to run because it is a mammalian genome. STAR alignment also took a couple of hours for just one alignment, the first diabetes sample. We created folders for the STAR alignments titled for each sample. For example, using command `mkdir diabetes_sample1_aligned_star_reads`, we stored all our files specific to the diabetes 1 sample.

We next run bamqc on the output BAM file from STAR to see the status of the alignments. We export the HTML to the computer using WinSCP and find that there is one issue with the aligned reads, the mapping quality distribution. The MAPQ score is 3 or less for about 35% of the reads, which a score of 3 means that the read is found to be aligned to 2 different locations, resulting in a low confidence of where it is actually mapped to. Therefore, after talking with Merv, we will be learning what to do with this situation after talking about quantification. The code we used to run bamqc is shown below.

```{bash,eval=FALSE}
/softlib/apps/EL7/BamQC/bin/bamqc /home/nib4003/ANGSD_2021_hw/final_project/diabetes_sample1_aligned_star_reads/diabetes_sample1_alignments.Aligned.sortedByCoord.out.bam --outdir /home/nib4003/ANGSD_2021_hw/final_project/diabetes_sample1_bamqc/
```

Below I include the bamqc file for myself when I come back and look at this document.

file:///C:/Users/nicky/Downloads/transfer_files/diabetes_sample1_alignments.Aligned.sortedByCoord.out_bamqc.html 